{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c524df",
   "metadata": {},
   "source": [
    "# Library functions\n",
    "\n",
    "The library functions are *exactly* the same as for the serial numpy version. If you write MPI code carefully, the parallelisation need not affect all of the code base. As here, you are often able to use the same routines to do the serial work (i.e. where there is no communications). The speedup comes because each process is operating on a smaller length of road, i.e. the value of `n` will be smaller here.\n",
    "\n",
    "`gettime` and `updatebcs` are no longer required as MPI has its own timer and the boundary values are now exchanged between processes using send and receive operations, but they are left it in as we want to use the same file as for the serial code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load trafficlib.py\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def initroad(road, density, seedval):\n",
    "\n",
    "    # Here we expect a road without halos\n",
    "\n",
    "    n = len(road)\n",
    "\n",
    "    np.random.seed(seedval)\n",
    "\n",
    "    rng = np.random.random(n)\n",
    "\n",
    "    road[0:n] = np.where(rng[:] < density, 1, 0)\n",
    "\n",
    "    ncar = np.sum(road)\n",
    "    \n",
    "    return ncar\n",
    "\n",
    "\n",
    "def updateroad(newroad, oldroad):\n",
    "\n",
    "    n = len(oldroad)-2\n",
    "\n",
    "    newroad[1:n+1] = np.where(oldroad[1:n+1]==0, oldroad[0:n], oldroad[2:n+2])\n",
    "\n",
    "    nmove = (newroad[1:n+1] != oldroad[1:n+1]).sum(dtype=int)\n",
    "    nmove = nmove / 2\n",
    "\n",
    "    return nmove\n",
    "\n",
    "\n",
    "def updatebcs(road):\n",
    "\n",
    "    n = len(road)-2\n",
    "\n",
    "    road[0]   = road[n]\n",
    "    road[n+1] = road[1]\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def gettime():\n",
    "\n",
    "    return time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f039ef",
   "metadata": {},
   "source": [
    "# Main program\n",
    "\n",
    "There are are a number of changes required to the main program.\n",
    "\n",
    "* We compute `size` and our `rank` - as is conventional, we nominate rank 0 as the controller (e.g. the process that prints any output)\n",
    "* The local number of cells `nlocal` is smaller than `ncell` by a factor of `size`. We still need an array `bigroad` to store the whole road as we do the initialisation in serial to ensure it is done identically to the serial numpy code. We also check for consistency - it would be straightforward to allow an arbitary length of road but this would make the code a little more complicated.\n",
    "* `bigroad` is scattered to all the processes. Note that *all* processes call `comm.Scatter` although they have different roles as the input data only exists on rank 0.\n",
    "* We compute our neighbours up and down, taking into account the periodic boundary conditions (i.e. the cars are on a roundabout).\n",
    "* The barrier calls are solely there to make sure that the processes start and finish the main calculation at the same time, which gives us more reliable runtimes. Removing all the barriers will have *no effect* on the correctness of the program.\n",
    "* Halos are exchanged up and down using a combined send and receive call `Sendrecv`.\n",
    "* Each process can compute how many cars moved on its section of road but to get the total number we need to sum up across all processes using `Allreduce`. To use the fast numpy MPI functions I use a numpy array of size 1 rather than a scalar.\n",
    "\n",
    "If you execute the program in the notebook it will run using a single process. As the time comparable to what you saw with the serial numpy version? Is the result the same, i.e. is the final velocity identical to before?\n",
    "\n",
    "The main parallel exercises are in the cell below the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f589f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of road is 10240000\n",
      "Number of iterations is 100\n",
      "Target density of cars is 0.52\n",
      "Running on 1 process(es)\n",
      "Initialising ...\n",
      "Actual Density of cars is 0.520013671875\n",
      "\n",
      "Scattering data ...\n",
      "... done\n",
      "\n",
      "At iteration 10 average velocity is 0.789451\n",
      "At iteration 20 average velocity is 0.837291\n",
      "At iteration 30 average velocity is 0.858276\n",
      "At iteration 40 average velocity is 0.870672\n",
      "At iteration 50 average velocity is 0.879025\n",
      "At iteration 60 average velocity is 0.885042\n",
      "At iteration 70 average velocity is 0.889747\n",
      "At iteration 80 average velocity is 0.893434\n",
      "At iteration 90 average velocity is 0.896450\n",
      "At iteration 100 average velocity is 0.898941\n",
      "\n",
      "Finished\n",
      "\n",
      "Time taken was 7.17 seconds\n",
      "Update rate was 142.88 MCOPs\n"
     ]
    }
   ],
   "source": [
    "# %load traffic.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "from trafficlib import initroad, updatebcs, updateroad, gettime\n",
    "\n",
    "def main(argv):\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "\n",
    "    size = comm.Get_size()\n",
    "    rank = comm.Get_rank()\n",
    "\n",
    "    # Simulation parameters\n",
    "    seedval = 5743\n",
    "    ncell = 10240000\n",
    "    maxiter = 1024000000//ncell\n",
    "    printfreq = maxiter//10\n",
    "\n",
    "    nlocal = ncell//size\n",
    "\n",
    "    # Check consistency\n",
    "\n",
    "    if (nlocal*size != ncell):\n",
    "        if (rank == 0):\n",
    "            print(f\"ERROR: ncell = {ncell} not a multiple of size = {size}\")\n",
    "        exit()\n",
    "\n",
    "    bigroad  = np.zeros(ncell,dtype=np.int32)\n",
    "    newroad  = np.zeros(nlocal+2,dtype=np.int32)\n",
    "    oldroad  = np.zeros(nlocal+2,dtype=np.int32)\n",
    "\n",
    "    sbuf = np.zeros(1)\n",
    "    rbuf = np.zeros(1)\n",
    "\n",
    "    density = 0.52\n",
    "\n",
    "    if (rank == 0):\n",
    "\n",
    "        print(f\"Length of road is {ncell}\")\n",
    "        print(f\"Number of iterations is {maxiter}\")\n",
    "        print(f\"Target density of cars is {density}\")\n",
    "        print(f\"Running on {size} process(es)\")\n",
    "\n",
    "        # Initialise road accordingly using random number generator\n",
    "        print(f\"Initialising ...\")\n",
    "\n",
    "        ncars = initroad(bigroad, density, seedval)\n",
    "\n",
    "        print(f\"Actual Density of cars is {format(float(ncars)/float(ncell))}\\n\")\n",
    "        print(f\"Scattering data ...\")\n",
    "\n",
    "    comm.Scatter(bigroad, oldroad[1:nlocal+1], root=0)\n",
    "\n",
    "    if (rank == 0):\n",
    "        print(f\"... done\\n\")\n",
    "\n",
    "    # Compute neighbours\n",
    "\n",
    "    rankup   = (rank + 1)\n",
    "    rankdown = (rank - 1)\n",
    "\n",
    "    # Wrap-around for cyclic boundary conditions, i.e. a roundabout\n",
    "\n",
    "    if (rankup == size):\n",
    "        rankup = 0\n",
    "\n",
    "    if (rankdown == -1):\n",
    "        rankdown = size-1\n",
    "\n",
    "    nmove = 0\n",
    "    nmovelocal = 0\n",
    "\n",
    "    comm.barrier()\n",
    "        \n",
    "    tstart = MPI.Wtime()\n",
    "\n",
    "    for iter in range(1, maxiter+1):\n",
    "\n",
    "        comm.Sendrecv(oldroad[nlocal:nlocal+1], dest=rankup,\n",
    "                      recvbuf=oldroad[0:1], source=rankdown)\n",
    "\n",
    "        comm.Sendrecv(oldroad[1:2], dest=rankdown,\n",
    "                      recvbuf=oldroad[nlocal+1:nlocal+2], source=rankup)\n",
    "\n",
    "        nmovelocal = updateroad(newroad, oldroad)\n",
    "\n",
    "        sbuf[0] = nmovelocal\n",
    "        comm.Allreduce(sbuf, rbuf)\n",
    "        nmove = rbuf[0]\n",
    "\n",
    "        # Copy new to old array\n",
    "        oldroad[1:nlocal+1] = newroad[1:nlocal+1]\n",
    "\n",
    "        if iter % printfreq == 0:\n",
    "\n",
    "            if (rank == 0):\n",
    "\n",
    "                print(f\"At iteration {iter} average velocity is {float(nmove)/float(ncars):.6f}\")\n",
    "\n",
    "    comm.barrier()\n",
    "\n",
    "    tstop = MPI.Wtime()\n",
    "\n",
    "    if (rank == 0):\n",
    "\n",
    "        print(f\"\\nFinished\\n\")\n",
    "        print(f\"Time taken was {tstop-tstart:.2f} seconds\")\n",
    "        print(f\"Update rate was {1.0e-6*ncell*maxiter/(tstop-tstart):.2f} MCOPs\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c414edd2",
   "metadata": {},
   "source": [
    "## Parallel exercises\n",
    "\n",
    "First, execute the program locally (using a shell escape) and check if the performance is the same as running in the notebook. You will not see continuous output - it will all appear at the end so there will be some delay.\n",
    "\n",
    "Mac and Linux users should use the first method of running. Windows users should use the second method as, without a timeout, Windows MPI does not seem to exit gracefully if the program crashes.\n",
    "\n",
    "To get the best performance and reliable runtimes you should make sure you are running as few other programs as possible on your laptop, e.g. quit as many browser tabs as possible, shut down Spotify and Twitter, ...\n",
    "\n",
    "* Now run on two processes using `-n 2`. Is the program any faster? Is the answer the same as before?\n",
    "* Run on 4 and 8 processes - does the code get any faster? It can be interesting to run a performance monitor while doing this as you should see multiple Python programs running at the same time (which may put a heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d73895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of road is 10240000\n",
      "Number of iterations is 100\n",
      "Target density of cars is 0.52\n",
      "Running on 1 process(es)\n",
      "Initialising ...\n",
      "Actual Density of cars is 0.520013671875\n",
      "\n",
      "Scattering data ...\n",
      "... done\n",
      "\n",
      "At iteration 10 average velocity is 0.789451\n",
      "At iteration 20 average velocity is 0.837291\n",
      "At iteration 30 average velocity is 0.858276\n",
      "At iteration 40 average velocity is 0.870672\n",
      "At iteration 50 average velocity is 0.879025\n",
      "At iteration 60 average velocity is 0.885042\n",
      "At iteration 70 average velocity is 0.889747\n",
      "At iteration 80 average velocity is 0.893434\n",
      "At iteration 90 average velocity is 0.896450\n",
      "At iteration 100 average velocity is 0.898941\n",
      "\n",
      "Finished\n",
      "\n",
      "Time taken was 7.00 seconds\n",
      "Update rate was 146.25 MCOPs\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 1 python traffic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b32bacbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of road is 10240000\n",
      "Number of iterations is 100\n",
      "Target density of cars is 0.52\n",
      "Running on 1 process(es)\n",
      "Initialising ...\n",
      "Actual Density of cars is 0.520013671875\n",
      "\n",
      "Scattering data ...\n",
      "... done\n",
      "\n",
      "At iteration 10 average velocity is 0.789451\n",
      "At iteration 20 average velocity is 0.837291\n",
      "At iteration 30 average velocity is 0.858276\n",
      "At iteration 40 average velocity is 0.870672\n",
      "At iteration 50 average velocity is 0.879025\n",
      "At iteration 60 average velocity is 0.885042\n",
      "At iteration 70 average velocity is 0.889747\n",
      "At iteration 80 average velocity is 0.893434\n",
      "At iteration 90 average velocity is 0.896450\n",
      "At iteration 100 average velocity is 0.898941\n",
      "\n",
      "Finished\n",
      "\n",
      "Time taken was 6.90 seconds\n",
      "Update rate was 148.38 MCOPs\n"
     ]
    }
   ],
   "source": [
    "!mpiexec /timeout 20 -n 1 python traffic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e66249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
